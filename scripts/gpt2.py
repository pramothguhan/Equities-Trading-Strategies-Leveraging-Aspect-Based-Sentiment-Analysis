# -*- coding: utf-8 -*-
"""GPT2 (4).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1x8bCZNO1Gzf0W9hr_u4tETJ-hSLp0hei
"""

import pandas as pd
from transformers import GPT2Tokenizer
import torch
from torch.utils.data import Dataset, DataLoader
from transformers import GPT2Model
import torch.nn as nn
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from transformers import AdamW

from google.colab import drive
drive.mount('/content/drive')

file_path = '/content/drive/MyDrive/post_processing_csv_data_v1.csv'

df = pd.read_csv(file_path)
df.head()

def split_dataset(df, split_ratio=0.8):
    """
    Splits the dataset into two portions sequentially based on the given ratio.

    Args:
    - df (pd.DataFrame): The input dataset.
    - split_ratio (float): Ratio for the first portion (default: 0.8 for an 80-20 split).

    Returns:
    - df_train (pd.DataFrame): The first portion of the dataset.
    - df_test (pd.DataFrame): The second portion of the dataset.
    """
    # Calculates the split index
    split_index = int(len(df) * split_ratio)

    # Splits the DataFrame
    df_train = df.iloc[:split_index]
    df_test = df.iloc[split_index:]

    return df_train, df_test


input_df, df_test = split_dataset(df, split_ratio=0.5)

print(f"Training set size: {len(input_df)}")
print(f"Test set size: {len(df_test)}")

# Checks for GPU availability and set the device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Initializes the tokenizer
tokenizer = GPT2Tokenizer.from_pretrained("gpt2")

# Sets the pad token to eos_token
tokenizer.pad_token = tokenizer.eos_token

def tokenize_data(df, max_len=128, batch_size=32):
    """
    Tokenizes the dataset for GPT or GPT-Neo and moves tensors to the GPU if available.
    """
    input_ids, attention_masks, labels = [], [], []

    # Process the data in batches
    for start_idx in range(0, len(df), batch_size):
        batch = df[start_idx:start_idx + batch_size]

        # Prepare inputs for the tokenizer
        encoded = tokenizer(
            text=[f"{row['aspect']} {tokenizer.sep_token} {row['context']}" for _, row in batch.iterrows()],
            padding='max_length',
            truncation=True,
            max_length=max_len,
            return_tensors="pt"
        )
        # Move tensors to the GPU
        input_ids.append(encoded['input_ids'].to(device))
        attention_masks.append(encoded['attention_mask'].to(device))
        labels.extend(batch['sentiment'].tolist())

    # Stack the tensors for all batches
    input_ids = torch.cat(input_ids, dim=0)
    attention_masks = torch.cat(attention_masks, dim=0)
    labels = torch.tensor(labels, device=device)

    return input_ids, attention_masks, labels

# Example usage
# Replace `input_df` with your actual DataFrame
input_ids, attention_masks, labels = tokenize_data(input_df, max_len=128)

print(f"Input IDs shape: {input_ids.shape}")
print(f"Attention Masks shape: {attention_masks.shape}")
print(f"Labels shape: {labels.shape}")

class AspectSentimentDataset(Dataset):
    def __init__(self, input_ids, attention_masks, labels):
        self.input_ids = input_ids
        self.attention_masks = attention_masks
        self.labels = labels

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, index):
        return {
            'input_ids': self.input_ids[index],
            'attention_mask': self.attention_masks[index],
            'label': self.labels[index]
        }

dataset = AspectSentimentDataset(input_ids, attention_masks, labels)

# Splits into training and validation sets
train_size = int(0.8 * len(dataset))
val_size = len(dataset) - train_size
train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])

# Creates DataLoaders
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16)

class AspectSentimentClassifier(nn.Module):
    def __init__(self, gpt2_model_name, num_classes):
        super(AspectSentimentClassifier, self).__init__()
        self.gpt2 = GPT2Model.from_pretrained(gpt2_model_name)
        for param in self.gpt2.parameters():
            param.requires_grad = False  # Freeze GPT-2

        self.classifier = nn.Sequential(
            nn.Linear(self.gpt2.config.hidden_size, 16),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(16, num_classes)
        )

    def forward(self, input_ids, attention_mask):
        outputs = self.gpt2(input_ids=input_ids, attention_mask=attention_mask)
        cls_token = outputs.last_hidden_state[:, -1, :]  # Use the last token's hidden state
        logits = self.classifier(cls_token)
        return logits

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

def train_model(model, train_loader, val_loader, optimizer, criterion, epochs=3):
    model.train()
    train_accuracies = []
    val_accuracies = []
    train_losses = []
    val_losses = []

    for epoch in range(epochs):
        # Training phase
        total_loss = 0
        all_predictions = []
        all_labels = []

        for batch in train_loader:
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['label'].to(device)

            optimizer.zero_grad()
            outputs = model(input_ids, attention_mask)

            # Calculates loss
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

            # Calculates predictions
            predictions = outputs.argmax(dim=1).detach().cpu().numpy()
            all_predictions.extend(predictions)
            all_labels.extend(labels.detach().cpu().numpy())

        # Calculates training metrics
        epoch_accuracy = accuracy_score(all_labels, all_predictions)
        train_accuracies.append(epoch_accuracy)
        train_losses.append(total_loss / len(train_loader))  # Average loss for training

        # Validation phase
        model.eval()
        val_predictions = []
        val_labels = []
        val_total_loss = 0

        with torch.no_grad():
            for batch in val_loader:
                input_ids = batch['input_ids'].to(device)
                attention_mask = batch['attention_mask'].to(device)
                labels = batch['label'].to(device)

                outputs = model(input_ids, attention_mask)

                # Calculates loss
                loss = criterion(outputs, labels)
                val_total_loss += loss.item()

                predictions = outputs.argmax(dim=1).detach().cpu().numpy()
                val_predictions.extend(predictions)
                val_labels.extend(labels.detach().cpu().numpy())

        val_accuracy = accuracy_score(val_labels, val_predictions)
        val_accuracies.append(val_accuracy)
        val_losses.append(val_total_loss / len(val_loader))

        model.train()

    return train_accuracies, val_accuracies, train_losses, val_losses, val_predictions, val_labels

def hyperparameter_tuning(model_class, train_loader, val_loader, criterion, epochs=5):
    best_val_accuracy = 0
    best_params = {}
    best_model = None
    best_train_accuracies = []
    best_val_accuracies = []
    best_train_losses = []
    best_val_losses = []
    best_val_predictions = []
    best_val_labels = []

    learning_rates = [1e-3, 1e-4, 1e-5]
    optimizers = [AdamW]

    for lr in learning_rates:
        for opt in optimizers:
            model = model_class().to(device)
            optimizer = opt(model.parameters(), lr=lr)

            train_accuracies, val_accuracies, train_losses, val_losses, val_predictions, val_labels = train_model(
                model, train_loader, val_loader, optimizer, criterion, epochs
            )

            if max(val_accuracies) > best_val_accuracy:
                best_val_accuracy = max(val_accuracies)
                best_params = {'optimizer': opt.__name__, 'learning_rate': lr}
                best_model = model
                best_train_accuracies = train_accuracies
                best_val_accuracies = val_accuracies
                best_train_losses = train_losses
                best_val_losses = val_losses
                best_val_predictions = val_predictions
                best_val_labels = val_labels

    precision = precision_score(best_val_labels, best_val_predictions, average='weighted')
    recall = recall_score(best_val_labels, best_val_predictions, average='weighted')
    f1 = f1_score(best_val_labels, best_val_predictions, average='weighted')

    print(f"Best Model Metrics:")
    print(f"Optimizer: {best_params['optimizer']}, Learning Rate: {best_params['learning_rate']}")
    print(f"Best Validation Accuracy: {best_val_accuracy:.4f}")
    print(f"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}")

    # Plots learning curves for the best model
    plt.figure(figsize=(14, 6))

    # Accuracy learning curve
    plt.subplot(1, 2, 1)
    plt.plot(range(1, epochs + 1), best_train_accuracies, label='Training Accuracy', marker='o')
    plt.plot(range(1, epochs + 1), best_val_accuracies, label='Validation Accuracy', marker='o')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.title('Accuracy Learning Curve (Best Model)')
    plt.legend()
    plt.grid()

    # Loss learning curve
    plt.subplot(1, 2, 2)
    plt.plot(range(1, epochs + 1), best_train_losses, label='Training Loss', marker='o')
    plt.plot(range(1, epochs + 1), best_val_losses, label='Validation Loss', marker='o')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.title('Loss Learning Curve (Best Model)')
    plt.legend()
    plt.grid()

    plt.tight_layout()
    plt.show()

    return best_model

# Parameters
GPT2_MODEL_NAME = "gpt2"
NUM_CLASSES = len(set(labels))  # Adjusts based on the number of unique labels in our dataset
EPOCHS = 5

# Initializes hyperparameter tuning
best_model = hyperparameter_tuning(
    lambda: AspectSentimentClassifier(gpt2_model_name=GPT2_MODEL_NAME, num_classes=NUM_CLASSES),
    train_loader,
    val_loader,
    nn.CrossEntropyLoss(),
    epochs=EPOCHS
)